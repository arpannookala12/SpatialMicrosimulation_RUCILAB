{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import logging\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rpy2.robjects as robjects\n",
    "from datetime import datetime\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects import pandas2ri, r, globalenv, StrVector, conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable pandas to R dataframe conversion\n",
    "pandas2ri.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting display to view all columns\n",
    "pd.set_option('display.max_columns', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore Warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfoFilter(logging.Filter):\n",
    "    def filter(self, record):\n",
    "        return record.levelno == logging.INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    filename='logs/results_log.log',\n",
    "    filemode='a',  # Append mode to add new entries without deleting old ones\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO  # Log messages of level INFO and above\n",
    ")\n",
    "# Get the logger object and add a filter to only accept INFO messages\n",
    "logger = logging.getLogger()\n",
    "info_filter = InfoFilter()\n",
    "logger.addFilter(info_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set State, County, MSA Code, and Stat Code\n",
    "statename = StrVector([\"NJ\"])\n",
    "countyname = StrVector([\"Middlesex\"])\n",
    "MSACODE = 35620\n",
    "STATECODE = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(MSACODE,STATECODE,ind_data):\n",
    "    twday_flag=None\n",
    "    twday_name=None\n",
    "    gender_name=None\n",
    "    # Filtering dataset based on MSA and STATE\n",
    "    if MSACODE is not None:\n",
    "        ind_data = ind_data[(ind_data['EST_MSA'] == MSACODE) & (ind_data['EST_ST'] == STATECODE)]\n",
    "    else:\n",
    "        ind_data = ind_data[(ind_data['EST_ST'] == STATECODE)]\n",
    "    # Calculating age based on the year the survey was conducted in\n",
    "    ind_data['AGE'] = 2024 - ind_data['TBIRTH_YEAR']\n",
    "    if 'TW_START' in ind_data.columns and 'EGENDER' in ind_data.columns:\n",
    "        print(ind_data.head())\n",
    "        # Filtering dataset based on variables of interest\n",
    "        variables_of_interest = [\"EST_ST\",\"EST_MSA\", \"MS\", \"RRACE\", \"TW_START\", \"EEDUC\", \"KINDWORK\", \"THHLD_NUMPER\", \"INCOME\", \"EGENDER\", \"AGE\", \"RHISPANIC\", \"ANYWORK\"]\n",
    "        ind_data = ind_data[variables_of_interest]\n",
    "        twday_flag = 1\n",
    "    elif 'TW_YN' in ind_data.columns and 'EGENDER' in ind_data.columns:\n",
    "        print(ind_data.head())\n",
    "        # Filtering dataset based on variables of interest\n",
    "        variables_of_interest = [\"EST_ST\",\"EST_MSA\", \"MS\", \"RRACE\", \"TW_YN\", \"EEDUC\", \"KINDWORK\", \"THHLD_NUMPER\", \"INCOME\", \"EGENDER\", \"AGE\", \"RHISPANIC\", \"ANYWORK\"]\n",
    "        ind_data = ind_data[variables_of_interest]\n",
    "        twday_flag = 2\n",
    "    elif 'ACTIVITY2' in ind_data.columns and 'EGENID_BIRTH' in ind_data.columns:\n",
    "        print(ind_data.head())\n",
    "        # Filtering dataset based on variables of interest\n",
    "        variables_of_interest = [\"EST_ST\",\"EST_MSA\", \"MS\", \"RRACE\", \"ACTIVITY2\", \"EEDUC\", \"KINDWORK\", \"THHLD_NUMPER\", \"INCOME\", \"EGENID_BIRTH\", \"AGE\", \"RHISPANIC\", \"ANYWORK\"]\n",
    "        ind_data = ind_data[variables_of_interest]\n",
    "        twday_flag = 3\n",
    "    else: \n",
    "        # Filtering dataset based on variables of interest\n",
    "        print(ind_data.head())\n",
    "        variables_of_interest = [\"EST_ST\",\"EST_MSA\", \"MS\", \"RRACE\", \"TWDAYS\", \"EEDUC\", \"KINDWORK\", \"THHLD_NUMPER\", \"INCOME\", \"EGENID_BIRTH\", \"AGE\", \"RHISPANIC\", \"ANYWORK\"]\n",
    "        ind_data = ind_data[variables_of_interest]\n",
    "        twday_flag = 4\n",
    "\n",
    "    if twday_flag==1:\n",
    "        twday_name='TW_START'\n",
    "        gender_name='EGENDER'\n",
    "    elif twday_flag==2:\n",
    "        twday_name='TW_YN'\n",
    "        gender_name='EGENDER'\n",
    "    elif twday_flag==3:\n",
    "        twday_name='ACTIVITY2'\n",
    "        gender_name='EGENID_BIRTH'\n",
    "    else:\n",
    "        twday_name='TWDAYS'\n",
    "        gender_name='EGENID_BIRTH'\n",
    "\n",
    "    # Checking for unique occurrences for chosen constraints\n",
    "    print(sorted(ind_data['AGE'].unique()))\n",
    "    print(sorted(ind_data['EEDUC'].unique()))\n",
    "    print(sorted(ind_data[gender_name].unique()))\n",
    "    print(sorted(ind_data['KINDWORK'].unique()))\n",
    "    print(sorted(ind_data['THHLD_NUMPER'].unique()))\n",
    "    print(sorted(ind_data[twday_name].unique()))\n",
    "\n",
    "    # Replacing -99 and -88 codes with NA to treat them as missing\n",
    "    ind_data['EEDUC'].replace([-99, -88], pd.NA, inplace=True)\n",
    "    ind_data[twday_name].replace([-99, -88], pd.NA, inplace=True)\n",
    "    ind_data['KINDWORK'].replace([-99, -88], pd.NA, inplace=True)\n",
    "    # Dropping rows with NA values, and filtering data to keep individuals aged 25 and above, and who are employed\n",
    "    ind_data.dropna(inplace=True)\n",
    "    ind_data = ind_data[ind_data['AGE'] >= 25]\n",
    "    ind_data = ind_data[ind_data['ANYWORK'] == 1]\n",
    "    # Checking for unique occurrences for chosen constraints after filtering\n",
    "    print(\"After filtering:\")\n",
    "    print(sorted(ind_data['AGE'].unique()))\n",
    "    print(sorted(ind_data['EEDUC'].unique()))\n",
    "    print(sorted(ind_data[gender_name].unique()))\n",
    "    print(sorted(ind_data['KINDWORK'].unique()))\n",
    "    print(sorted(ind_data['THHLD_NUMPER'].unique()))\n",
    "    print(sorted(ind_data[twday_name].unique()))\n",
    "    # Fixed arrays\n",
    "    brks = [25, 30, 35, 40, 45, 50, 55, 60, 62, 65, 67, 70, 75, 80, 85, float('inf')]\n",
    "    labs = [\n",
    "    \"25 to 29 years\", \"30 to 34 years\", \"35 to 39 years\", \"40 to 44 years\", \"45 to 49 years\",\n",
    "    \"50 to 54 years\", \"55 to 59 years\", \"60 and 61 years\", \"62 to 64 years\", \"65 and 66 years\",\n",
    "    \"67 to 69 years\", \"70 to 74 years\", \"75 to 79 years\", \"80 to 84 years\", \"85 years and over\"\n",
    "    ]\n",
    "    # Input unique values\n",
    "    unique_values = ind_data['AGE'].unique()\n",
    "    # Convert unique_values to a set for faster lookup\n",
    "    unique_values_set = set(unique_values)\n",
    "    # Age category dictionary\n",
    "    age_cat_dict = {\n",
    "    \"25 to 29 years\": [25, 26, 27, 28, 29],\n",
    "    \"30 to 34 years\": [30, 31, 32, 33, 34],\n",
    "    \"35 to 39 years\": [35, 36, 37, 38, 39],\n",
    "    \"40 to 44 years\": [40, 41, 42, 43, 44],\n",
    "    \"45 to 49 years\": [45, 46, 47, 48, 49],\n",
    "    \"50 to 54 years\": [50, 51, 52, 53, 54],\n",
    "    \"55 to 59 years\": [55, 56, 57, 58, 59],\n",
    "    \"60 and 61 years\": [60, 61],\n",
    "    \"62 to 64 years\": [62, 63, 64],\n",
    "    \"65 and 66 years\": [65, 66],\n",
    "    \"67 to 69 years\": [67, 68, 69],\n",
    "    \"70 to 74 years\": [70, 71, 72, 73, 74],\n",
    "    \"75 to 79 years\": [75, 76, 77, 78, 79],\n",
    "    \"80 to 84 years\": [80, 81, 82, 83, 84],\n",
    "    \"85 years and over\": list(range(85, 200))\n",
    "    }\n",
    "    # Create new bins and labels based on the presence of unique values\n",
    "    new_brks = [brks[0]]\n",
    "    new_labs = []\n",
    "    for label, ages in age_cat_dict.items():\n",
    "        # Check if there are any values in the current age range\n",
    "        if any(age in unique_values_set for age in ages):\n",
    "            # Append the end value of the current bin\n",
    "            if label != \"85 years and over\":\n",
    "                new_brks.append(brks[len(new_labs) + 1])\n",
    "            else:\n",
    "                new_brks.append(float('inf'))\n",
    "            new_labs.append(label)\n",
    "    # Output the updated bins and labels\n",
    "    print(\"Updated Bins:\", new_brks)\n",
    "    print(\"Updated Labels:\", new_labs)\n",
    "    # Encoding/ recategorizing constraints\n",
    "    ind_data['AGE'] = pd.cut(ind_data['AGE'], bins=new_brks, labels=new_labs, right=False)\n",
    "    ind_data[gender_name] = ind_data[gender_name].replace({1: 'Male', 2: 'Female'})\n",
    "    ind_data['EEDUC'] = ind_data['EEDUC'].replace({1: 'Less than high school',2: 'Some high school', 3: 'High school graduate or equivalent (for example GED)', 4: \"Some college, but degree not received or is in progress\", 5: \"Associate's degree (for example AA, AS)\", 6: \"Bachelor's degree (for example BA, BS, AB)\", 7: \"Graduate degree (for example master's, professional, doctorate)\"})\n",
    "    ind_data['KINDWORK'] = ind_data['KINDWORK'].replace({1: 'Government', 2: 'Private company', 3: 'Non-profit organization including tax exempt and charitable organizations', 4: 'Self-employed', 5: 'Working in a family business'})\n",
    "    if twday_flag==1:    \n",
    "        ind_data[twday_name] = ind_data[twday_name].replace({1:\"Yes, at least one adult substituted some or all of their typical in-person work for telework\",2:\"No, no adults substituted their typical in-person work for telework\",3:\"No, there has been no change in telework\"})\n",
    "    elif twday_flag==2 or twday_flag==3:\n",
    "        ind_data[twday_name] = ind_data[twday_name].replace({1:\"Yes\", 2:\"No\"})\n",
    "    else:\n",
    "        ind_data[twday_name] = ind_data[twday_name].replace({1: 'Yes, for 1-2 days', 2: 'Yes, for 3-4 days', 3: 'Yes, for 5 or more days', 4: 'No'})\n",
    "    ind_data['INCOME'] = ind_data['INCOME'].replace({1: 'Less than $25,000', 2: '$25,000 - $34,999', 3: '$35,000 - $49,999', 4: '$50,000 - $74,999', 5: '$75,000 - $99,999', 6: '$100,000 - $149,999', 7: '$150,000 - $199,999', 8: '$200,000 and above'})\n",
    "    ind_data['MS'] = ind_data['MS'].replace({1: 'Now married', 2: 'Widowed', 3: 'Divorced', 4: 'Separated', 5: 'Never married'})\n",
    "    # Creating subsets of the data\n",
    "    ind_full = ind_data[[gender_name, \"AGE\", \"EEDUC\", \"KINDWORK\", \"INCOME\", \"MS\", \"THHLD_NUMPER\", twday_name]]\n",
    "    ind_data = ind_data[[\"EST_ST\", gender_name, \"AGE\", \"EEDUC\", \"KINDWORK\", \"MS\", \"THHLD_NUMPER\", \"INCOME\", twday_name]]\n",
    "    # Checking for unique occurrences for chosen constraints after recategorizing\n",
    "    print(sorted(ind_data['AGE'].unique()))\n",
    "    print(sorted(ind_data['EEDUC'].unique()))\n",
    "    print(sorted(ind_data[gender_name].unique()))\n",
    "    print(sorted(ind_data['KINDWORK'].unique()))\n",
    "    print(sorted(ind_data[twday_name].unique()))\n",
    "    edu_labs = ind_data['EEDUC'].unique()\n",
    "    print(edu_labs)\n",
    "    work_labs = ind_data['KINDWORK'].unique()\n",
    "    print(work_labs)\n",
    "    return ind_data,ind_full,new_brks,new_labs,edu_labs,work_labs,gender_name,twday_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_age_func(new_brks,new_labs,statename,countyname):\n",
    "  # Load the R script containing the function\n",
    "  r.source('age_sexcons.R')  # Replace 'age_sexcons.R' with the path to your R script\n",
    "  # Reference the function from the R script\n",
    "  process_acs_age_sex_data = globalenv['process_acs_age_sex_data']\n",
    "  # Call the R function from Python\n",
    "  result = process_acs_age_sex_data(new_brks, new_labs, statename, countyname)\n",
    "  # Since the result is expected to be a data.frame, convert it to Pandas DataFrame using conversion context\n",
    "  with conversion.localconverter(robjects.default_converter + pandas2ri.converter):\n",
    "    con_age_sex_df = robjects.conversion.rpy2py(result)\n",
    "  # Display the result\n",
    "  con_age = con_age_sex_df['con_age']\n",
    "  con_sex = con_age_sex_df['con_sex']\n",
    "  con_age_sex_zero_row = con_age_sex_df['zero_row_indices']\n",
    "  print(con_age.head())\n",
    "  print(con_sex.head())\n",
    "  print(con_age_sex_zero_row)\n",
    "  return con_age, con_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_edu_func(edu_labs,statename,countyname):\n",
    "  r.source(\"educons.R\")\n",
    "  process_edu_data = globalenv[\"process_edu_data\"]\n",
    "  result = process_edu_data(edu_labs,statename,countyname)\n",
    "  # Since the result is expected to be a data.frame, convert it to Pandas DataFrame using conversion context\n",
    "  with conversion.localconverter(robjects.default_converter + pandas2ri.converter):\n",
    "    con_edu_df = robjects.conversion.rpy2py(result)\n",
    "\n",
    "  # Display the result\n",
    "  con_edu = con_edu_df['con_edu']\n",
    "  con_edu_zero_row = con_edu_df['zero_row_indices']\n",
    "  print(con_edu.head())\n",
    "  print(con_edu_zero_row)\n",
    "  return con_edu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_work_func(work_labs,statename,countyname):\n",
    "  r.source(\"kindworkcons.R\")\n",
    "  process_work_data = globalenv[\"process_work_data\"]\n",
    "  result = process_work_data(work_labs,statename,countyname)\n",
    "  # Since the result is expected to be a data.frame, convert it to Pandas DataFrame using conversion context\n",
    "  with conversion.localconverter(robjects.default_converter + pandas2ri.converter):\n",
    "    con_work_df = robjects.conversion.rpy2py(result)\n",
    "\n",
    "  # Display the result\n",
    "  con_work = con_work_df['con_work']\n",
    "  con_work_zero_row = con_work_df['zero_row_indices']\n",
    "  print(con_work.head())\n",
    "  print(con_work_zero_row)\n",
    "  return con_work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constraint_build(con_age,con_sex,con_edu,con_work):\n",
    "    # Checking the Total sums of each constraint\n",
    "    sum_con_age = con_age.sum(numeric_only=True).sum()\n",
    "    sum_con_sex = con_sex.sum(numeric_only=True).sum()\n",
    "    sum_con_edu = con_edu.sum(numeric_only=True).sum()\n",
    "    sum_con_work = con_work.sum(numeric_only=True).sum()\n",
    "    print(\"Sum of age:{}\".format(sum_con_age))\n",
    "    print(\"Sum of sex:{}.\".format(sum_con_sex))\n",
    "    print(\"Sum of education:{}\".format(sum_con_edu))\n",
    "    print(\"Sum of work:{}\".format(sum_con_work))\n",
    "    # List of dataframes\n",
    "    dataframes = [con_age, con_sex, con_edu, con_work]\n",
    "    # Step 1: Find common GEOID values across all dataframes\n",
    "    common_geoids = set(dataframes[0]['GEOID'])\n",
    "    for df in dataframes[1:]:\n",
    "        common_geoids.intersection_update(df['GEOID'])\n",
    "    # Step 2: Filter each dataframe to keep only the rows with common GEOID values\n",
    "    filtered_dataframes = [df[df['GEOID'].isin(common_geoids)] for df in dataframes]\n",
    "    # Assign the filtered dataframes back to the original variables\n",
    "    con_age, con_sex, con_edu ,con_work = filtered_dataframes\n",
    "    geoids = con_age[['GEOID']]\n",
    "    print(geoids)\n",
    "    con_age = con_age.drop(con_age.columns[0], axis=1)\n",
    "    con_sex = con_sex.drop(con_sex.columns[0], axis=1)\n",
    "    con_edu = con_edu.drop(con_edu.columns[0], axis=1)\n",
    "    con_work = con_work.drop(con_work.columns[0], axis=1)\n",
    "    # Checking the Total sums of each constraint\n",
    "    sum_con_age = con_age.sum(numeric_only=True).sum()\n",
    "    sum_con_sex = con_sex.sum(numeric_only=True).sum()\n",
    "    sum_con_edu = con_edu.sum(numeric_only=True).sum()\n",
    "    sum_con_work = con_work.sum(numeric_only=True).sum()\n",
    "    print(\"Sum of age:{}\".format(sum_con_age))\n",
    "    print(\"Sum of sex:{}.\".format(sum_con_sex))\n",
    "    print(\"Sum of education:{}\".format(sum_con_edu))\n",
    "    print(\"Sum of work:{}\".format(sum_con_work))\n",
    "    con_age = con_age.reset_index(drop=True)\n",
    "    con_sex = con_sex.reset_index(drop=True)\n",
    "    con_edu = con_edu.reset_index(drop=True)\n",
    "    con_work = con_work.reset_index(drop=True)\n",
    "    # Compute total minimum attribute counts for each row\n",
    "    # min_con = min(con_age,con_sex,con_edu,con_work)\n",
    "    total_income_counts = con_work.sum(axis=1)\n",
    "    print(total_income_counts)\n",
    "    # Define the adjustment and correction function\n",
    "    def adjust_and_correct(df, target_totals):\n",
    "        # Compute the initial proportions\n",
    "        proportions = df.div(df.sum(axis=1), axis=0)\n",
    "        \n",
    "        # Apply target totals using proportions\n",
    "        adjusted_values = proportions.mul(target_totals, axis=0)\n",
    "        rounded_values = adjusted_values.round()\n",
    "        \n",
    "        # Efficiently correct residuals\n",
    "        residuals = target_totals - rounded_values.sum(axis=1)\n",
    "        for idx in residuals[residuals != 0].index:\n",
    "            sign = np.sign(residuals[idx])\n",
    "            row_proportions = proportions.loc[idx]\n",
    "            sorted_indices = row_proportions.sort_values(ascending=False).index\n",
    "            for col in sorted_indices:\n",
    "                if sign == 1 and residuals[idx] > 0:\n",
    "                    max_add = target_totals[idx] - rounded_values.loc[idx].sum()\n",
    "                    add_value = min(max_add, residuals[idx])\n",
    "                    rounded_values.loc[idx, col] += add_value\n",
    "                    residuals[idx] -= add_value\n",
    "                elif sign == -1 and residuals[idx] < 0:\n",
    "                    max_sub = rounded_values.loc[idx, col]\n",
    "                    sub_value = min(max_sub, -residuals[idx])\n",
    "                    rounded_values.loc[idx, col] -= sub_value\n",
    "                    residuals[idx] += sub_value\n",
    "                if residuals[idx] == 0:\n",
    "                    break\n",
    "        \n",
    "        # Validation (optional but recommended)\n",
    "        validation_passed = (rounded_values.sum(axis=1) == target_totals).all()\n",
    "        return {\n",
    "            'rounded_values': rounded_values,\n",
    "            'validation_passed': validation_passed\n",
    "        }\n",
    "\n",
    "    # Apply the function to your datasets\n",
    "    results_edu = adjust_and_correct(con_edu, total_income_counts)\n",
    "    results_age = adjust_and_correct(con_age, total_income_counts)\n",
    "    results_sex = adjust_and_correct(con_sex, total_income_counts)\n",
    "\n",
    "    # Output the results to check\n",
    "    print(\"Adjusted and Corrected Education Data:\")\n",
    "    print(results_edu['rounded_values'])\n",
    "    print(\"\\nAdjusted and Corrected Age Data:\")\n",
    "    print(results_age['rounded_values'])\n",
    "    print(\"\\nAdjusted and Corrected Sex Data:\")\n",
    "    print(results_sex['rounded_values'])\n",
    "    # Assign corrected values back to the original dataframes\n",
    "    con_age = results_age['rounded_values']\n",
    "    con_sex = results_sex['rounded_values']\n",
    "    con_edu = results_edu['rounded_values']\n",
    "    # con_work = results_work['rounded_values']\n",
    "\n",
    "    # Sum the total values of the different corrected constraints\n",
    "    sum_con_age = con_age.values.sum()\n",
    "    sum_con_sex = con_sex.values.sum()\n",
    "    sum_con_edu = con_edu.values.sum()\n",
    "    sum_con_work = con_work.values.sum()\n",
    "\n",
    "    # Display the total sum of corrected constraints\n",
    "    print(\"Total Sum of Corrected Age Constraints:\")\n",
    "    print(sum_con_age)\n",
    "    print(\"\\nTotal Sum of Corrected Sex Constraints:\")\n",
    "    print(sum_con_sex)\n",
    "    print(\"\\nTotal Sum of Corrected Education Constraints:\")\n",
    "    print(sum_con_edu)\n",
    "    print(\"\\nTotal Sum of Corrected Work Constraints:\")\n",
    "    print(sum_con_work)\n",
    "    logger.info(f\"Sum of all Constraints: {sum_con_age}\")\n",
    "\n",
    "    # Compare row sums of different corrected constraints\n",
    "    print(\"\\nRow sums comparison between corrected constraints:\")\n",
    "    print((con_work.sum(axis=1) == con_age.sum(axis=1)).all())\n",
    "    print((con_work.sum(axis=1) == con_sex.sum(axis=1)).all())\n",
    "    print((con_work.sum(axis=1) == con_work.sum(axis=1)).all())\n",
    "    print((con_work.sum(axis=1) == con_edu.sum(axis=1)).all())\n",
    "    # Create constraint dataframe by combining all constraints\n",
    "    cons = pd.concat([con_age, con_sex, con_edu, con_work], axis=1)\n",
    "    return cons,con_age,con_sex,con_edu,con_work,geoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_trs(x):\n",
    "    # Convert input to a flat array\n",
    "    xv = np.array(x).flatten()\n",
    "    \n",
    "    # Integer part of the weight\n",
    "    xint = np.floor(xv).astype(int)\n",
    "    \n",
    "    # Decimal part of the weight\n",
    "    r = xv - xint\n",
    "    \n",
    "    # Deficit population (rounded sum of remaining weights)\n",
    "    deficit = int(np.round(np.sum(r)))\n",
    "    \n",
    "    # Top up the weights (+1 applied)\n",
    "    if deficit > 0:\n",
    "        topup_indices = np.random.choice(len(xv), size=deficit, p=r/np.sum(r), replace=False)\n",
    "        for idx in topup_indices:\n",
    "            xint[idx] += 1\n",
    "\n",
    "    # Reshape and set dimnames if needed\n",
    "    xint = xint.reshape(x.shape)\n",
    "    \n",
    "    return xint\n",
    "\n",
    "# Function 2: Equivalent to `int_expand_vector` in R\n",
    "def int_expand_vector(x):\n",
    "    # Create an array of indices\n",
    "    indices = np.arange(1, len(x) + 1)\n",
    "    \n",
    "    # Repeat each index according to the rounded weight\n",
    "    expanded_vector = np.repeat(indices, np.round(x).astype(int))\n",
    "    \n",
    "    return expanded_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipfmain(cons,con_age,con_sex,con_edu,con_work,ind_data,ind_full,geoids,gender_name,twday_name):\n",
    "    # Creating dummy variables for each column with 0 and 1 representation\n",
    "    cat_age = pd.get_dummies(ind_data['AGE'], prefix='AGE', drop_first=False).astype(int)\n",
    "    cat_sex = pd.get_dummies(ind_data[gender_name], prefix=gender_name, drop_first=False).astype(int)\n",
    "    cat_edu = pd.get_dummies(ind_data['EEDUC'], prefix='EEDUC', drop_first=False).astype(int)\n",
    "    cat_work = pd.get_dummies(ind_data['KINDWORK'], prefix='KINDWORK', drop_first=False).astype(int)\n",
    "\n",
    "    # Getting the dimensions of each dummy matrix\n",
    "    print(cat_age.shape)\n",
    "    print(cat_sex.shape)\n",
    "    print(cat_edu.shape)\n",
    "    print(cat_work.shape)\n",
    "    # Combine the dummy matrices horizontally (similar to `cbind()` in R)\n",
    "    ind_cat = pd.concat([cat_age, cat_sex, cat_edu, cat_work], axis=1)\n",
    "\n",
    "    # Display the first few rows of the resulting DataFrame\n",
    "    ind_cat.head()\n",
    "    # Calculate column sums of ind_cat\n",
    "    ind_agg = ind_cat.sum(axis=0)\n",
    "    ind_agg\n",
    "\n",
    "    # Number of rows in `cons`\n",
    "    n_zone = cons.shape[0]\n",
    "    print(n_zone)\n",
    "\n",
    "    # Number of rows in `ind_data`\n",
    "    n_ind = ind_data.shape[0]\n",
    "    print(n_ind)\n",
    "\n",
    "    # Number of columns in `con_age`\n",
    "    n_age = con_age.shape[1]\n",
    "    print(n_age)\n",
    "\n",
    "    # Number of columns in `con_sex`\n",
    "    n_sex = con_sex.shape[1]\n",
    "    print(n_sex)\n",
    "\n",
    "    # Number of columns in `con_edu`\n",
    "    n_edu = con_edu.shape[1]\n",
    "    print(n_edu)\n",
    "\n",
    "    # Number of columns in `con_work`\n",
    "    n_work = con_work.shape[1]\n",
    "    print(n_work)\n",
    "\n",
    "    # First Iteration with age constraint\n",
    "    epsilon = 1e-10  # Small constant to prevent division by zero\n",
    "\n",
    "    # Step 1: Initialize Weights\n",
    "    weights = np.ones((n_ind, n_zone))\n",
    "\n",
    "    # Create independent copies for multiple weights\n",
    "    weights1 = weights.copy()\n",
    "    weights2 = weights.copy()\n",
    "    weights3 = weights.copy()\n",
    "    weights4 = weights.copy()\n",
    "    weights5 = weights.copy()\n",
    "    weights6 = weights.copy()\n",
    "\n",
    "    print(\"Weights dimensions:\", weights.shape)\n",
    "    # Step 2: Create `ind_agg0` Equivalent\n",
    "    ind_agg0 = np.array([ind_agg * 1 for x in cons.values])\n",
    "\n",
    "    # Create DataFrame for consistency and assign column names\n",
    "    ind_agg0 = pd.DataFrame(ind_agg0, columns=cons.columns)\n",
    "    ind_agg0.head()\n",
    "    \n",
    "    # Step 3: Update Weights (`weights1`) with Nested Loops\n",
    "    for j in range(n_zone):\n",
    "        for i in range(n_age):\n",
    "            # Find the indices where the corresponding value in `ind_cat` is 1\n",
    "            index = ind_cat.iloc[:, i] == 1\n",
    "\n",
    "            # Apply epsilon correction to prevent division by zero\n",
    "            adjusted_denominator = ind_agg0.iloc[j, i] + epsilon\n",
    "            if adjusted_denominator <= 0:\n",
    "                adjusted_denominator = epsilon\n",
    "\n",
    "            # Update weights1 where the index condition is True\n",
    "            weights1[index, j] = weights[index, j] * con_age.iloc[j, i] / adjusted_denominator\n",
    "\n",
    "    weights1_df = pd.DataFrame(weights1)\n",
    "    weights1_df.head()\n",
    "    # Step 4: Initialize `ind_agg` Variables with NaN\n",
    "    ind_agg1 = ind_agg0.copy() * np.nan\n",
    "    ind_agg2 = ind_agg0.copy() * np.nan\n",
    "    ind_agg3 = ind_agg0.copy() * np.nan\n",
    "    ind_agg4 = ind_agg0.copy() * np.nan\n",
    "    ind_agg5 = ind_agg0.copy() * np.nan\n",
    "    ind_agg6 = ind_agg0.copy() * np.nan\n",
    "    # Step 5: Update `ind_agg1` by Summing Conditioned Multiplications\n",
    "    for i in range(n_zone):\n",
    "        # Calculate column sums after element-wise multiplication of `ind_cat` and `weights1[:, i]`\n",
    "        ind_agg1.iloc[i, :] = (ind_cat.values * weights1[:, i].reshape(-1, 1)).sum(axis=0)\n",
    "\n",
    "    ind_agg1.head()\n",
    "    # Step 6: Calculate and Compare Row Sums\n",
    "    # Calculate row sums for columns 0 to 13 (which corresponds to columns 1 to 14 in R)\n",
    "    row_sums_ind_agg1 = ind_agg1.iloc[:, 0:n_age-1].sum(axis=1)\n",
    "    row_sums_cons = cons.iloc[:, 0:n_age-1].sum(axis=1)\n",
    "\n",
    "    # Compare row sums\n",
    "    row_sums_equal = row_sums_ind_agg1 == row_sums_cons\n",
    "\n",
    "    # Display row sums and the comparison results\n",
    "    print(\"Row sums for ind_agg1:\\n\", row_sums_ind_agg1)\n",
    "    print(\"Row sums for cons:\\n\", row_sums_cons)\n",
    "    print(\"Are row sums equal:\\n\", row_sums_equal)\n",
    "\n",
    "    # Second Iteration with Age & Sex constraint\n",
    "    epsilon = 1e-10  # Small constant to prevent division by zero\n",
    "    for j in range(n_zone):\n",
    "        for i in range(n_age+n_sex):\n",
    "            # Find the indices where the corresponding value in `ind_cat` is 1\n",
    "            index = ind_cat.iloc[:, i] == 1\n",
    "\n",
    "            # Apply epsilon correction to prevent division by zero\n",
    "            adjusted_denominator = ind_agg1.iloc[j, i] + epsilon\n",
    "            if adjusted_denominator <= 0:\n",
    "                adjusted_denominator = epsilon\n",
    "\n",
    "            # Update weights1 where the index condition is True\n",
    "            weights2[index, j] = weights1[index, j] * cons.iloc[j, i] / adjusted_denominator\n",
    "\n",
    "    # Convert to DataFrame and display the first few rows\n",
    "    weights2_df = pd.DataFrame(weights2)\n",
    "    weights2_df.head()\n",
    "    for i in range(n_zone):\n",
    "    # Calculate column sums after element-wise multiplication of `ind_cat` and `weights2[:, i]`\n",
    "        ind_agg2.iloc[i, :] = (ind_cat.values * weights2[:, i].reshape(-1, 1)).sum(axis=0)\n",
    "\n",
    "    ind_agg2.head()\n",
    "    row_sums_ind_agg2 = ind_agg2.iloc[:, n_age-1:(n_age+n_sex)-1].sum(axis=1)\n",
    "    row_sums_cons = cons.iloc[:, n_age-1:(n_age+n_sex)-1].sum(axis=1)\n",
    "\n",
    "    # Compare row sums\n",
    "    row_sums_equal = row_sums_ind_agg2 == row_sums_cons\n",
    "\n",
    "    # Display row sums and the comparison results\n",
    "    print(\"Row sums for ind_agg2:\\n\", row_sums_ind_agg2)\n",
    "    print(\"Row sums for cons:\\n\", row_sums_cons)\n",
    "    print(\"Are row sums equal:\\n\", row_sums_equal)\n",
    "\n",
    "    # Third iteration with Age, Sex, and Education constraint\n",
    "    epsilon = 1e-10  # Small constant to prevent division by zero\n",
    "    for j in range(n_zone):\n",
    "        for i in range(n_age+n_sex+n_edu):\n",
    "            # Find the indices where the corresponding value in `ind_cat` is 1\n",
    "            index = ind_cat.iloc[:, i] == 1\n",
    "\n",
    "            # Apply epsilon correction to prevent division by zero\n",
    "            adjusted_denominator = ind_agg2.iloc[j, i] + epsilon\n",
    "            if adjusted_denominator <= 0:\n",
    "                adjusted_denominator = epsilon\n",
    "\n",
    "            # Update weights1 where the index condition is True\n",
    "            weights3[index, j] = weights2[index, j] * cons.iloc[j, i] / adjusted_denominator\n",
    "\n",
    "    # Convert to DataFrame and display the first few rows\n",
    "    weights3_df = pd.DataFrame(weights3)\n",
    "    weights3_df.head()\n",
    "    for i in range(n_zone):\n",
    "    # Calculate column sums after element-wise multiplication of `ind_cat` and `weights1[:, i]`\n",
    "        ind_agg3.iloc[i, :] = (ind_cat.values * weights3[:, i].reshape(-1, 1)).sum(axis=0)\n",
    "\n",
    "    ind_agg3.head()\n",
    "    row_sums_ind_agg3 = ind_agg3.iloc[:, (n_age+n_sex)-1:(n_age+n_sex+n_edu)-1].sum(axis=1)\n",
    "    row_sums_cons = cons.iloc[:, (n_age+n_sex)-1:(n_age+n_sex+n_edu)-1].sum(axis=1)\n",
    "\n",
    "    # Compare row sums\n",
    "    row_sums_equal = row_sums_ind_agg3 == row_sums_cons\n",
    "\n",
    "    # Display row sums and the comparison results\n",
    "    print(\"Row sums for ind_agg3:\\n\", row_sums_ind_agg3)\n",
    "    print(\"Row sums for cons:\\n\", row_sums_cons)\n",
    "    print(\"Are row sums equal:\\n\", row_sums_equal)\n",
    "\n",
    "    # Fourth iteration with Age, Sex, Education, and Work constraint\n",
    "    epsilon = 1e-10  # Small constant to prevent division by zero\n",
    "    for j in range(n_zone):\n",
    "        for i in range(n_age+n_sex+n_edu+n_work):\n",
    "            # Find the indices where the corresponding value in `ind_cat` is 1\n",
    "            index = ind_cat.iloc[:, i] == 1\n",
    "\n",
    "            # Apply epsilon correction to prevent division by zero\n",
    "            adjusted_denominator = ind_agg3.iloc[j, i] + epsilon\n",
    "            if adjusted_denominator <= 0:\n",
    "                adjusted_denominator = epsilon\n",
    "\n",
    "            # Update weights1 where the index condition is True\n",
    "            weights4[index, j] = weights3[index, j] * cons.iloc[j, i] / adjusted_denominator\n",
    "\n",
    "    # Convert to DataFrame and display the first few rows\n",
    "    weights4_df = pd.DataFrame(weights4)\n",
    "    weights4_df.head()\n",
    "    for i in range(n_zone):\n",
    "    # Calculate column sums after element-wise multiplication of `ind_cat` and `weights1[:, i]`\n",
    "        ind_agg4.iloc[i, :] = (ind_cat.values * weights4[:, i].reshape(-1, 1)).sum(axis=0)\n",
    "\n",
    "    ind_agg4.head()\n",
    "    row_sums_ind_agg4 = ind_agg4.iloc[:, (n_age+n_sex+n_edu)-1:(n_age+n_sex+n_edu+n_work)-1].sum(axis=1)\n",
    "    row_sums_cons = cons.iloc[:, (n_age+n_sex+n_edu)-1:(n_age+n_sex+n_edu+n_work)-1].sum(axis=1)\n",
    "\n",
    "    # Compare row sums\n",
    "    row_sums_equal = row_sums_ind_agg4 == row_sums_cons\n",
    "\n",
    "    # Display row sums and the comparison results\n",
    "    print(\"Row sums for ind_agg4:\\n\", row_sums_ind_agg4)\n",
    "    print(\"Row sums for cons:\\n\", row_sums_cons)\n",
    "    print(\"Are row sums equal:\\n\", row_sums_equal)\n",
    "    # Convert dataframes to vectors\n",
    "    def vec(x):\n",
    "        return np.array(x).flatten()  # Converts DataFrame/array to a 1D numeric array\n",
    "\n",
    "    # Calculate correlations\n",
    "    cor_agg0 = np.corrcoef(vec(ind_agg0), vec(cons))[0, 1]\n",
    "    cor_agg1 = np.corrcoef(vec(ind_agg1), vec(cons))[0, 1]\n",
    "    cor_agg2 = np.corrcoef(vec(ind_agg2), vec(cons))[0, 1]\n",
    "    cor_agg3 = np.corrcoef(vec(ind_agg3), vec(cons))[0, 1]\n",
    "    cor_agg4 = np.corrcoef(vec(ind_agg4), vec(cons))[0, 1]\n",
    "\n",
    "    logger.info(f\"Final Correlation between Aggregate and Constraint Dataset: {cor_agg4}\")\n",
    "\n",
    "    # Print correlations\n",
    "    print(\"Correlation between ind_agg0 and cons:\", cor_agg0)\n",
    "    print(\"Correlation between ind_agg1 and cons:\", cor_agg1)\n",
    "    print(\"Correlation between ind_agg2 and cons:\", cor_agg2)\n",
    "    print(\"Correlation between ind_agg3 and cons:\", cor_agg3)\n",
    "    print(\"Correlation between ind_agg4 and cons:\", cor_agg4)\n",
    "\n",
    "        # Initialize an empty DataFrame to store results (equivalent to NULL in R)\n",
    "    ints_df = pd.DataFrame()\n",
    "\n",
    "    # Loop through zones to expand the weights and create a DataFrame for each zone\n",
    "    for i in range(n_zone):\n",
    "        # Apply `int_trs` to round the weights and obtain the expanded vector\n",
    "        int_weight1 = int_expand_vector(int_trs(weights4[:, i]))\n",
    "        \n",
    "        # Create a DataFrame with the expanded indices from `ind_full`\n",
    "        data_frame = ind_full.iloc[int_weight1 - 1, :].copy()  # Subtract 1 to adjust for Python's 0-based indexing\n",
    "        \n",
    "        # Add a `GEOID` column with the appropriate identifier for each row\n",
    "        data_frame['GEOID'] = str(geoids.iloc[i]['GEOID'])\n",
    "        \n",
    "        # Append `data_frame` to `ints_df` (equivalent to `rbind` in R)\n",
    "        ints_df = pd.concat([ints_df, data_frame], ignore_index=True)\n",
    "\n",
    "    # Select specific columns (equivalent to `ints_df <- ints_df[, c(...)]` in R)\n",
    "    ints_df = ints_df[[\"GEOID\", \"AGE\", gender_name, \"EEDUC\", \"KINDWORK\", twday_name]]\n",
    "    logger.info(f\"Final ints_df population: {ints_df.shape[0]}\")\n",
    "    # Display the resulting DataFrame\n",
    "    print(ints_df.head())\n",
    "    return ints_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(ints_df):\n",
    "    print(ints_df['TWDAYS'].value_counts())\n",
    "    print(ints_df['AGE'].value_counts())\n",
    "    print(ints_df['EGENID_BIRTH'].value_counts())\n",
    "    print(ints_df['KINDWORK'].value_counts())\n",
    "    # Step 1: Data Cleaning and Preparation\n",
    "    data = ints_df.copy()\n",
    "\n",
    "    # Check for missing values\n",
    "    missing_values = data.isna().sum()\n",
    "    print(\"Missing values:\\n\", missing_values)\n",
    "\n",
    "    # Ensure 'TWDAYS' is consistent and treated as a categorical variable\n",
    "    data['TWDAYS'] = data['TWDAYS'].str.strip().str.lower()\n",
    "    # Ensure 'AGE', 'EEDUC', 'EGENID_BIRTH', and 'KINDWORK' are treated as categorical variables\n",
    "    data['AGE'] = data['AGE'].astype('category')\n",
    "    data['EEDUC'] = data['EEDUC'].astype('category')\n",
    "    data['EGENID_BIRTH'] = data['EGENID_BIRTH'].astype('category')\n",
    "    data['KINDWORK'] = data['KINDWORK'].astype('category')\n",
    "    # Calculate frequency of telework days\n",
    "    twday_counts = data['TWDAYS'].value_counts()\n",
    "    print(\"Frequency of telework days:\\n\", twday_counts)\n",
    "\n",
    "    # Summarize by age group\n",
    "    age_twday_summary = data.groupby(['AGE', 'TWDAYS']).size().unstack(fill_value=0)\n",
    "    print(\"Age and Telework Days Summary:\\n\", age_twday_summary)\n",
    "\n",
    "    # Calculate proportions by age group\n",
    "    age_twday_proportion = data.groupby(['AGE', 'TWDAYS']).size().reset_index(name='Count')\n",
    "    age_twday_proportion['Proportion'] = age_twday_proportion.groupby('AGE')['Count'].transform(lambda x: x / x.sum())\n",
    "    age_twday_proportion = age_twday_proportion.pivot(index='AGE', columns='TWDAYS', values='Proportion').fillna(0)\n",
    "    print(\"Age and Telework Days Proportion:\\n\", age_twday_proportion)\n",
    "\n",
    "    # Summarize by gender\n",
    "    gender_twday_summary = data.groupby(['EGENID_BIRTH', 'TWDAYS']).size().unstack(fill_value=0)\n",
    "    print(\"Gender and Telework Days Summary:\\n\", gender_twday_summary)\n",
    "\n",
    "    # Calculate proportions by gender\n",
    "    gender_twday_proportion = data.groupby(['EGENID_BIRTH', 'TWDAYS']).size().reset_index(name='Count')\n",
    "    gender_twday_proportion['Proportion'] = gender_twday_proportion.groupby('EGENID_BIRTH')['Count'].transform(lambda x: x / x.sum())\n",
    "    gender_twday_proportion = gender_twday_proportion.pivot(index='EGENID_BIRTH', columns='TWDAYS', values='Proportion').fillna(0)\n",
    "    print(\"Gender and Telework Days Proportion:\\n\", gender_twday_proportion)\n",
    "\n",
    "    # Summarize by educational attainment\n",
    "    education_twday_summary = data.groupby(['EEDUC', 'TWDAYS']).size().unstack(fill_value=0)\n",
    "    print(\"Education and Telework Days Summary:\\n\", education_twday_summary)\n",
    "\n",
    "    # Calculate proportions by educational attainment\n",
    "    education_twday_proportion = data.groupby(['EEDUC', 'TWDAYS']).size().reset_index(name='Count')\n",
    "    education_twday_proportion['Proportion'] = education_twday_proportion.groupby('EEDUC')['Count'].transform(lambda x: x / x.sum())\n",
    "    education_twday_proportion = education_twday_proportion.pivot(index='EEDUC', columns='TWDAYS', values='Proportion').fillna(0)\n",
    "    print(\"Education and Telework Days Proportion:\\n\", education_twday_proportion)\n",
    "\n",
    "    # Summarize by kind of work\n",
    "    kindwork_twday_summary = data.groupby(['KINDWORK', 'TWDAYS']).size().unstack(fill_value=0)\n",
    "    print(\"Kindwork and Telework Days Summary:\\n\", kindwork_twday_summary)\n",
    "\n",
    "    # Calculate proportions by kind of work\n",
    "    kindwork_twday_proportion = data.groupby(['KINDWORK', 'TWDAYS']).size().reset_index(name='Count')\n",
    "    kindwork_twday_proportion['Proportion'] = kindwork_twday_proportion.groupby('KINDWORK')['Count'].transform(lambda x: x / x.sum())\n",
    "    kindwork_twday_proportion = kindwork_twday_proportion.pivot(index='KINDWORK', columns='TWDAYS', values='Proportion').fillna(0)\n",
    "    print(\"Kindwork and Telework Days Proportion:\\n\", kindwork_twday_proportion)\n",
    "    # Visualization for telework days by age group\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    age_twday_proportion.plot(kind='bar', stacked=True)\n",
    "    plt.title('Proportion of Telework Days by Age Group')\n",
    "    plt.xlabel('Age Group')\n",
    "    plt.ylabel('Proportion of Telework Days')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend(title='Telework Days', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Visualization for telework days by gender\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    gender_twday_proportion.plot(kind='bar', stacked=True)\n",
    "    plt.title('Proportion of Telework Days by Gender')\n",
    "    plt.xlabel('Gender')\n",
    "    plt.ylabel('Proportion of Telework Days')\n",
    "    plt.legend(title='Telework Days', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Visualization for telework days by educational attainment\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    education_twday_proportion.plot(kind='bar', stacked=True)\n",
    "    plt.title('Proportion of Telework Days by Educational Attainment')\n",
    "    plt.xlabel('Educational Attainment')\n",
    "    plt.ylabel('Proportion of Telework Days')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend(title='Telework Days', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Visualization for telework days by kind of work\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    kindwork_twday_proportion.plot(kind='bar', stacked=True)\n",
    "    plt.title('Proportion of Telework Days by Kind of Work')\n",
    "    plt.xlabel('Kind of Work')\n",
    "    plt.ylabel('Proportion of Telework Days')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend(title='Telework Days', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all tables:\n",
      "['Phase_2_HPS_Week13_PUF_CSV(August19_August31)2020_pulse2020_puf_13', 'Phase_2_HPS_Week14_PUF_CSV(September2_September14)2020_pulse2020_puf_14', 'Phase_2_HPS_Week15_PUF_CSV(September16_September28)2020_pulse2020_puf_15', 'Phase_2_HPS_Week16_PUF_CSV(September30_October12)2020_pulse2020_puf_16', 'Phase_2_HPS_Week17_PUF_CSV(October14_October26)2020_pulse2020_puf_17', 'Phase_3_HPS_Week18_PUF_CSV(October28_November9)2020_pulse2020_puf_18', 'Phase_3_HPS_Week19_PUF_CSV(November11_November23)2020_pulse2020_puf_19', 'Phase_3_HPS_Week20_PUF_CSV(November25_December7)2020_pulse2020_puf_20', 'Phase_3_HPS_Week21_PUF_CSV(December9_December21)2020_pulse2020_puf_21', 'Phase_3_HPS_Week22_PUF_CSV(January6_January18)2021_pulse2021_puf_22', 'Phase_3_HPS_Week23_PUF_CSV(January20_February1)2021_pulse2021_puf_23', 'Phase_3_HPS_Week24_PUF_CSV(February3_February15)2021_pulse2021_puf_24', 'Phase_3_HPS_Week25_PUF_CSV(February17_March1)2021_pulse2021_puf_25', 'Phase_3_HPS_Week26_PUF_CSV(March3_March15)2021_pulse2021_puf_26', 'Phase_3_HPS_Week27_PUF_CSV(March17_March29)2021_pulse2021_puf_27', 'Phase_3_1_HPS_Week28_PUF_CSV(April14_April26)2021_pulse2021_puf_28', 'Phase_3_1_HPS_Week29_PUF_CSV(April28_May10)2021_pulse2021_puf_29', 'Phase_3_1_HPS_Week30_PUF_CSV(May12_May24)2021_pulse2021_puf_30', 'Phase_3_1_HPS_Week31_PUF_CSV(May26_June7)2021_pulse2021_puf_31', 'Phase_3_1_HPS_Week32_PUF_CSV(June9_June21)2021_pulse2021_puf_32', 'Phase_3_1_HPS_Week33_PUF_CSV(June23_July5)2021_pulse2021_puf_33', 'Phase_3_10_HPS_Week61_PUF_CSV(August23_September4)2023_pulse2023_puf_61', 'Phase_3_10_HPS_Week62_PUF_CSV(September20_October2)2023_pulse2023_puf_62', 'Phase_3_10_HPS_Week63_PUF_CSV(October18_October30)2023_pulse2023_puf_63', 'Phase_3_2_HPS_Week34_PUF_CSV(July21_August2)2021_pulse2021_puf_34', 'Phase_3_2_HPS_Week35_PUF_CSV(August4_August16)2021_pulse2021_puf_35', 'Phase_3_2_HPS_Week36_PUF_CSV(August18_August30)2021_pulse2021_puf_36', 'Phase_3_2_HPS_Week37_PUF_CSV(September1_September13)2021_pulse2021_puf_37', 'Phase_3_2_HPS_Week38_PUF_CSV(September15_September27)2021_pulse2021_puf_38', 'Phase_3_2_HPS_Week39_PUF_CSV(September29_October11)2021_pulse2021_puf_39', 'Phase_3_3_HPS_Week40_PUF_CSV(December1_December13)2021_pulse2021_puf_40', 'Phase_3_3_HPS_Week41_PUF_CSV(December29_2021_January10_2022)_pulse2022_puf_41', 'Phase_3_3_HPS_Week42_PUF_CSV(January26_February7)2022_pulse2022_puf_42', 'Phase_3_4_HPS_Week43_PUF_CSV(March2_March14)2022_pulse2022_puf_43', 'Phase_3_4_HPS_Week44_PUF_CSV(March30_April11)2022_pulse2022_puf_44', 'Phase_3_4_HPS_Week45_PUF_CSV(April27_May9)2022_pulse2022_puf_45', 'Phase_3_5_HPS_Week46_PUF_CSV(June1_June13)2022_pulse2022_puf_46', 'Phase_3_5_HPS_Week47_PUF_CSV(June29_July11)2022_pulse2022_puf_47', 'Phase_3_5_HPS_Week48_PUF_CSV(July27_August8)2022_pulse2022_puf_48', 'Phase_3_6_HPS_Week49_PUF_CSV(September14_September28)2022_pulse2022_puf_49', 'Phase_3_6_HPS_Week50_PUF_CSV(October5_October17)2022_pulse2022_puf_50', 'Phase_3_6_HPS_Week51_PUF_CSV(November2_November14)2022_pulse2022_puf_51', 'Phase_3_7_HPS_Week52_PUF_CSV(December9_December19)2022_pulse2022_puf_52', 'Phase_3_7_HPS_Week53_PUF_CSV(January4_January16)2023_pulse2023_puf_53', 'Phase_3_7_HPS_Week54_PUF_CSV(February1_February13)2023_pulse2023_puf_54', 'Phase_3_8_HPS_Week55_PUF_CSV(March1_March13)2023_pulse2023_puf_55', 'Phase_3_8_HPS_Week56_PUF_CSV(March_29_April10)2023_pulse2023_puf_56', 'Phase_3_8_HPS_Week57_PUF_CSV(April26_May8)2023_pulse2023_puf_57', 'Phase_3_9_HPS_Week58_PUF_CSV(June7_June19)2023_pulse2023_puf_58', 'Phase_3_9_HPS_Week59_PUF_CSV(June28_July10)2023_pulse2023_puf_59', 'Phase_3_9_HPS_Week60_PUF_CSV(July26_August7)2023_pulse2023_puf_60', 'Phase_4_0_HPS_Phase4Cycle01_PUF_CSV(January9_February5)2024_hps_04_00_01_puf', 'Phase_4_0_HPS_Phase4Cycle02_PUF_CSV(February6_March4)2024_hps_04_00_02_puf', 'Phase_4_0_HPS_Phase4Cycle03_PUF_CSV(March5_April1)2024_hps_04_00_03_puf', 'Phase_4_1_HPS_Phase4_1Cycle04_PUF_CSV(April2_April29)2024_hps_04_01_04_puf', 'Phase_4_1_HPS_Phase4_1Cycle05_PUF_CSV(April30_May27)2024_hps_04_01_05_puf', 'Phase_4_1_HPS_Phase4_1Cycle06_PUF_CSV(May28_June24)2024_hps_04_01_06_puf', 'Phase_4_1_HPS_Phase4_1Cycle07_PUF_CSV(June25_July22)2024_hps_04_01_07_puf', 'Phase_4_2_HPS_Phase4_2Cycle08_PUF_CSV(July23_August19)2024_hps_04_02_08_puf', 'Phase_4_2_HPS_Phase4_2Cycle09_PUF_CSV(Aug20_Sep16)2024_hps_04_02_09_puf']\n"
     ]
    }
   ],
   "source": [
    "# Code to loop over all phase files\n",
    "# Mechanism to save results from different phases\n",
    "# Mechanism to combine results from different phases for an entire location\n",
    "db_path = 'HPS_phases_Data.db'\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(db_path)\n",
    "# Query to get all table names\n",
    "query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables_df = pd.read_sql_query(query, conn)\n",
    "# Display the list of all table names\n",
    "print(\"List of all tables:\")\n",
    "print(tables_df['name'].to_list())\n",
    "tables_df_list = tables_df['name'].to_list()\n",
    "# Close the database connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Edit cell to run IPF on all phase files\n",
    "# conn = sqlite3.connect(db_path)\n",
    "# for table in tables_df_list:\n",
    "#     table_name = table\n",
    "#     print(table_name)\n",
    "#     ind_data = pd.read_sql_query(f'SELECT * FROM \"{table_name}\"', conn)\n",
    "#     ind_data_new,ind_full_new,new_brks,new_labs,edu_labs,work_labs,gender_name,twday_name = filter_data(MSACODE,STATECODE,ind_data)\n",
    "#     con_age,con_sex = con_age_func(new_brks,new_labs,statename,countyname)\n",
    "#     con_edu = con_edu_func(edu_labs,statename,countyname)\n",
    "#     con_work = con_work_func(work_labs,statename,countyname)\n",
    "#     cons,con_age,con_sex,con_edu,con_work,geoids = constraint_build(con_age,con_sex,con_edu,con_work)\n",
    "#     ints_df = ipfmain(cons,con_age,con_sex,con_edu,con_work,ind_data_new,ind_full_new,geoids,gender_name,twday_name)\n",
    "#     ints_df.to_csv(\"New Jersey/Middlesex County, NJ/{}_synthetic_population.csv\".format(table_name))\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          SCRAM  CYCLE  EST_ST  EST_MSA  REGION       HWEIGHT       PWEIGHT  \\\n",
      "39   P090000040      9      34  35620.0       1   2973.320238   2784.759749   \n",
      "135  P090000136      9      34  35620.0       1   2890.352895  13535.269928   \n",
      "186  P090000187      9      34  35620.0       1  12640.706480  23678.129353   \n",
      "217  P090000218      9      34  35620.0       1   3907.462392  10978.982873   \n",
      "224  P090000225      9      34  35620.0       1   1647.102097   3085.294052   \n",
      "\n",
      "     TBIRTH_YEAR  ABIRTH_YEAR  RHISPANIC  AHISPANIC  RRACE  ARACE  EEDUC  \\\n",
      "39          1941            2          1          2      1      2      3   \n",
      "135         1970            2          1          2      1      2      4   \n",
      "186         1977            2          2          2      1      1      3   \n",
      "217         1963            2          2          2      1      2      6   \n",
      "224         1957            2          1          2      1      2      7   \n",
      "\n",
      "     AEDUC  MS  EGENID_BIRTH  AGENID_BIRTH  SEXUAL_ORIENTATION_RV  \\\n",
      "39       2   2             2             2                      2   \n",
      "135      2   1             2             2                      2   \n",
      "186      2   1             2             2                      2   \n",
      "217      2   3             1             2                      2   \n",
      "224      2   1             1             2                      2   \n",
      "\n",
      "     THHLD_NUMPER  ...  ACCESS_TRANSP  NEEDS_TRANSP1  NEEDS_TRANSP2  \\\n",
      "39              1  ...              1            -88            -88   \n",
      "135             5  ...              1            -88            -88   \n",
      "186             3  ...              1            -88            -88   \n",
      "217             4  ...              1            -88            -88   \n",
      "224             2  ...              1            -88            -88   \n",
      "\n",
      "     NEEDS_TRANSP3  NEEDS_TRANSP4  NEEDS_TRANSP5  NEEDS_TRANSP6  \\\n",
      "39             -88            -88            -88            -88   \n",
      "135            -88            -88            -88            -88   \n",
      "186            -88            -88            -88            -88   \n",
      "217            -88            -88            -88            -88   \n",
      "224            -88            -88            -88            -88   \n",
      "\n",
      "     NEEDS_TRANSP7  HOME_INTERNET  MOBILE_INTERNET  REDUCED_INT1  \\\n",
      "39             -88              1                2           -99   \n",
      "135            -88              1                1           -99   \n",
      "186            -88            -88              -88           -88   \n",
      "217            -88              1                1             1   \n",
      "224            -88              1                1           -99   \n",
      "\n",
      "     REDUCED_INT2  REDUCED_INT3  REDUCED_INT4  REDUCED_INT5  REDUCED_INT6  \\\n",
      "39            -99           -99           -99           -99             1   \n",
      "135           -99           -99           -99           -99             1   \n",
      "186           -88           -88           -88           -88           -88   \n",
      "217           -99           -99           -99           -99           -99   \n",
      "224           -99           -99           -99           -99             1   \n",
      "\n",
      "     CANCEL_INTERNET  SOCIAL1  SOCIAL2  AGE  \n",
      "39               -88        2        4   83  \n",
      "135              -88        3        1   54  \n",
      "186              -88        1        5   47  \n",
      "217                2        4        3   61  \n",
      "224              -88        2        5   67  \n",
      "\n",
      "[5 rows x 221 columns]\n",
      "[np.int64(21), np.int64(22), np.int64(23), np.int64(24), np.int64(25), np.int64(26), np.int64(27), np.int64(28), np.int64(29), np.int64(30), np.int64(31), np.int64(32), np.int64(33), np.int64(34), np.int64(35), np.int64(36), np.int64(37), np.int64(38), np.int64(39), np.int64(40), np.int64(41), np.int64(42), np.int64(43), np.int64(44), np.int64(45), np.int64(46), np.int64(47), np.int64(48), np.int64(49), np.int64(50), np.int64(51), np.int64(52), np.int64(53), np.int64(54), np.int64(55), np.int64(56), np.int64(57), np.int64(58), np.int64(59), np.int64(60), np.int64(61), np.int64(62), np.int64(63), np.int64(64), np.int64(65), np.int64(66), np.int64(67), np.int64(68), np.int64(69), np.int64(70), np.int64(71), np.int64(72), np.int64(73), np.int64(74), np.int64(75), np.int64(76), np.int64(77), np.int64(78), np.int64(79), np.int64(80), np.int64(81), np.int64(82), np.int64(83), np.int64(84), np.int64(85), np.int64(88)]\n",
      "[np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
      "[np.int64(1), np.int64(2)]\n",
      "[np.int64(-99), np.int64(-88), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)]\n",
      "[np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(10)]\n",
      "[np.int64(-99), np.int64(1), np.int64(2), np.int64(3), np.int64(4)]\n",
      "After filtering:\n",
      "[np.int64(25), np.int64(26), np.int64(27), np.int64(28), np.int64(29), np.int64(30), np.int64(31), np.int64(32), np.int64(33), np.int64(34), np.int64(35), np.int64(36), np.int64(37), np.int64(38), np.int64(39), np.int64(40), np.int64(41), np.int64(42), np.int64(43), np.int64(44), np.int64(45), np.int64(46), np.int64(47), np.int64(48), np.int64(49), np.int64(50), np.int64(51), np.int64(52), np.int64(53), np.int64(54), np.int64(55), np.int64(56), np.int64(57), np.int64(58), np.int64(59), np.int64(60), np.int64(61), np.int64(62), np.int64(63), np.int64(64), np.int64(65), np.int64(66), np.int64(67), np.int64(68), np.int64(69), np.int64(70), np.int64(71), np.int64(72), np.int64(73), np.int64(74), np.int64(75), np.int64(76), np.int64(77), np.int64(78), np.int64(79), np.int64(80), np.int64(83)]\n",
      "[np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
      "[np.int64(1), np.int64(2)]\n",
      "[1, 2, 3, 4, 5]\n",
      "[np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8)]\n",
      "[1, 2, 3, 4]\n",
      "Updated Bins: [25, 30, 35, 40, 45, 50, 55, 60, 62, 65, 67, 70, 75, 80, 85]\n",
      "Updated Labels: ['25 to 29 years', '30 to 34 years', '35 to 39 years', '40 to 44 years', '45 to 49 years', '50 to 54 years', '55 to 59 years', '60 and 61 years', '62 to 64 years', '65 and 66 years', '67 to 69 years', '70 to 74 years', '75 to 79 years', '80 to 84 years']\n",
      "['25 to 29 years', '30 to 34 years', '35 to 39 years', '40 to 44 years', '45 to 49 years', '50 to 54 years', '55 to 59 years', '60 and 61 years', '62 to 64 years', '65 and 66 years', '67 to 69 years', '70 to 74 years', '75 to 79 years', '80 to 84 years']\n",
      "[\"Associate's degree (for example AA, AS)\", \"Bachelor's degree (for example BA, BS, AB)\", \"Graduate degree (for example master's, professional, doctorate)\", 'High school graduate or equivalent (for example GED)', 'Less than high school', 'Some college, but degree not received or is in progress', 'Some high school']\n",
      "['Female', 'Male']\n",
      "['Government', 'Non-profit organization including tax exempt and charitable organizations', 'Private company', 'Self-employed', 'Working in a family business']\n",
      "['No', 'Yes, for 1-2 days', 'Yes, for 3-4 days', 'Yes, for 5 or more days']\n",
      "['High school graduate or equivalent (for example GED)'\n",
      " \"Graduate degree (for example master's, professional, doctorate)\"\n",
      " \"Bachelor's degree (for example BA, BS, AB)\"\n",
      " 'Some college, but degree not received or is in progress'\n",
      " \"Associate's degree (for example AA, AS)\" 'Less than high school'\n",
      " 'Some high school']\n",
      "['Private company'\n",
      " 'Non-profit organization including tax exempt and charitable organizations'\n",
      " 'Self-employed' 'Government' 'Working in a family business']\n",
      "$Male\n",
      "[1] \"B01001_002\"\n",
      "\n",
      "$Female\n",
      "[1] \"B01001_026\"\n",
      "\n",
      "$`25 to 29 years`\n",
      "[1] \"B01001_011\" \"B01001_035\"\n",
      "\n",
      "$`30 to 34 years`\n",
      "[1] \"B01001_012\" \"B01001_036\"\n",
      "\n",
      "$`35 to 39 years`\n",
      "[1] \"B01001_013\" \"B01001_037\"\n",
      "\n",
      "$`40 to 44 years`\n",
      "[1] \"B01001_014\" \"B01001_038\"\n",
      "\n",
      "$`45 to 49 years`\n",
      "[1] \"B01001_015\" \"B01001_039\"\n",
      "\n",
      "$`50 to 54 years`\n",
      "[1] \"B01001_016\" \"B01001_040\"\n",
      "\n",
      "$`55 to 59 years`\n",
      "[1] \"B01001_017\" \"B01001_041\"\n",
      "\n",
      "$`60 and 61 years`\n",
      "[1] \"B01001_018\" \"B01001_042\"\n",
      "\n",
      "$`62 to 64 years`\n",
      "[1] \"B01001_019\" \"B01001_043\"\n",
      "\n",
      "$`65 and 66 years`\n",
      "[1] \"B01001_020\" \"B01001_044\"\n",
      "\n",
      "$`67 to 69 years`\n",
      "[1] \"B01001_021\" \"B01001_045\"\n",
      "\n",
      "$`70 to 74 years`\n",
      "[1] \"B01001_022\" \"B01001_046\"\n",
      "\n",
      "$`75 to 79 years`\n",
      "[1] \"B01001_023\" \"B01001_047\"\n",
      "\n",
      "$`80 to 84 years`\n",
      "[1] \"B01001_024\" \"B01001_048\"\n",
      "\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      " [1] 140 143 144 233 482 490 524 558 561 574\n",
      "[1] 10\n",
      "# A tibble: 566 x 15\n",
      "   GEOID     `25 to 29 years` `30 to 34 years` `35 to 39 years` `40 to 44 years`\n",
      "   <chr>                <dbl>            <dbl>            <dbl>            <dbl>\n",
      " 1 34023000~              3.5              0.5            194.              37.5\n",
      " 2 34023000~             56.5             72.5            306.             168. \n",
      " 3 34023000~            144.             252.              62.5              0.5\n",
      " 4 34023000~            102.              80.5            126.              58.5\n",
      " 5 34023000~             24.5             61.5              0.5             68.5\n",
      " 6 34023000~             43.5             74.5              0.5              0.5\n",
      " 7 34023000~            104.             114.             196.              75.5\n",
      " 8 34023000~             12.5             67.5             52.5             55.5\n",
      " 9 34023000~            304.             158.              31.5            160. \n",
      "10 34023000~            104.              53.5             22.5             51.5\n",
      "# i 556 more rows\n",
      "# i 10 more variables: `45 to 49 years` <dbl>, `50 to 54 years` <dbl>,\n",
      "#   `55 to 59 years` <dbl>, `60 and 61 years` <dbl>, `62 to 64 years` <dbl>,\n",
      "#   `65 and 66 years` <dbl>, `67 to 69 years` <dbl>, `70 to 74 years` <dbl>,\n",
      "#   `75 to 79 years` <dbl>, `80 to 84 years` <dbl>\n",
      "# i Use `print(n = ...)` to see more rows\n",
      "# A tibble: 566 x 3\n",
      "   GEOID          Male Female\n",
      "   <chr>         <dbl>  <dbl>\n",
      " 1 340230001011  264.   698. \n",
      " 2 340230001012  760.   640. \n",
      " 3 340230001021  414.   518. \n",
      " 4 340230001022  828.   760. \n",
      " 5 340230001023  210.   312. \n",
      " 6 340230001024   55.5   62.5\n",
      " 7 340230002001  722.   644. \n",
      " 8 340230002002  334.   278. \n",
      " 9 340230002003 1024.  1202. \n",
      "10 340230002004  318.   418. \n",
      "# i 556 more rows\n",
      "# i Use `print(n = ...)` to see more rows\n",
      "          GEOID  25 to 29 years  30 to 34 years  35 to 39 years  \\\n",
      "1  340230001011             3.5             0.5           193.5   \n",
      "2  340230001012            56.5            72.5           305.5   \n",
      "3  340230001021           144.5           252.5            62.5   \n",
      "4  340230001022           102.5            80.5           126.5   \n",
      "5  340230001023            24.5            61.5             0.5   \n",
      "\n",
      "   40 to 44 years  45 to 49 years  50 to 54 years  55 to 59 years  \\\n",
      "1            37.5           210.5           185.5           113.5   \n",
      "2           167.5            57.5           112.5            93.5   \n",
      "3             0.5            22.5            76.5            98.5   \n",
      "4            58.5            80.5           211.5           459.5   \n",
      "5            68.5            23.5            69.5            81.5   \n",
      "\n",
      "   60 and 61 years  62 to 64 years  65 and 66 years  67 to 69 years  \\\n",
      "1             18.5            36.5             53.5             0.5   \n",
      "2             28.5           139.5             44.5           122.5   \n",
      "3             25.5            68.5             47.5           115.5   \n",
      "4             88.5            90.5             27.5            61.5   \n",
      "5              0.5            25.5              0.5            12.5   \n",
      "\n",
      "   70 to 74 years  75 to 79 years  80 to 84 years  \n",
      "1            39.5            49.5            25.5  \n",
      "2           167.5            38.5             0.5  \n",
      "3             0.5            22.5             0.5  \n",
      "4            81.5            37.5            87.5  \n",
      "5            27.5            79.5            51.5  \n",
      "          GEOID   Male  Female\n",
      "1  340230001011  264.5   697.5\n",
      "2  340230001012  760.5   640.5\n",
      "3  340230001021  413.5   518.5\n",
      "4  340230001022  827.5   760.5\n",
      "5  340230001023  209.5   311.5\n",
      "[140 143 144 233 482 490 524 558 561 574]\n",
      "$`Less than high school`\n",
      " [1] \"B15003_002\" \"B15003_003\" \"B15003_004\" \"B15003_005\" \"B15003_006\"\n",
      " [6] \"B15003_007\" \"B15003_008\" \"B15003_009\" \"B15003_010\" \"B15003_011\"\n",
      "[11] \"B15003_012\"\n",
      "\n",
      "$`Some high school`\n",
      "[1] \"B15003_013\" \"B15003_014\" \"B15003_015\" \"B15003_016\"\n",
      "\n",
      "$`High school graduate or equivalent (for example GED)`\n",
      "[1] \"B15003_017\" \"B15003_018\"\n",
      "\n",
      "$`Some college, but degree not received or is in progress`\n",
      "[1] \"B15003_019\" \"B15003_020\"\n",
      "\n",
      "$`Associate's degree (for example AA, AS)`\n",
      "[1] \"B15003_021\"\n",
      "\n",
      "$`Bachelor's degree (for example BA, BS, AB)`\n",
      "[1] \"B15003_022\"\n",
      "\n",
      "$`Graduate degree (for example master's, professional, doctorate)`\n",
      "[1] \"B15003_023\" \"B15003_024\" \"B15003_025\"\n",
      "\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      " [1] 140 143 144 233 482 490 524 558 561 574\n",
      "[1] 10\n",
      "# A tibble: 566 x 8\n",
      "   GEOID        Less than high schoo~1 `Some high school` High school graduate~2\n",
      "   <chr>                         <dbl>              <dbl>                  <dbl>\n",
      " 1 340230001011                    0.5                0.5                  346. \n",
      " 2 340230001012                   40.5               27.5                  358. \n",
      " 3 340230001021                   22.5              118.                   150. \n",
      " 4 340230001022                   23.5               28.5                  496. \n",
      " 5 340230001023                   11.5                0.5                  112. \n",
      " 6 340230001024                    0.5                0.5                    0.5\n",
      " 7 340230002001                  162.               174.                   238. \n",
      " 8 340230002002                   64.5                0.5                  286. \n",
      " 9 340230002003                  202.                57.5                  700. \n",
      "10 340230002004                    0.5              140.                   228. \n",
      "# i 556 more rows\n",
      "# i abbreviated names: 1: `Less than high school`,\n",
      "#   2: `High school graduate or equivalent (for example GED)`\n",
      "# i 4 more variables:\n",
      "#   `Some college, but degree not received or is in progress` <dbl>,\n",
      "#   `Associate's degree (for example AA, AS)` <dbl>,\n",
      "#   `Bachelor's degree (for example BA, BS, AB)` <dbl>, ...\n",
      "# i Use `print(n = ...)` to see more rows\n",
      "          GEOID  Less than high school  Some high school  \\\n",
      "1  340230001011                    0.5               0.5   \n",
      "2  340230001012                   40.5              27.5   \n",
      "3  340230001021                   22.5             117.5   \n",
      "4  340230001022                   23.5              28.5   \n",
      "5  340230001023                   11.5               0.5   \n",
      "\n",
      "   High school graduate or equivalent (for example GED)  \\\n",
      "1                                              345.5      \n",
      "2                                              358.5      \n",
      "3                                              149.5      \n",
      "4                                              496.5      \n",
      "5                                              111.5      \n",
      "\n",
      "   Some college, but degree not received or is in progress  \\\n",
      "1                                              119.5         \n",
      "2                                              257.5         \n",
      "3                                              123.5         \n",
      "4                                              342.5         \n",
      "5                                              152.5         \n",
      "\n",
      "   Associate's degree (for example AA, AS)  \\\n",
      "1                                     47.5   \n",
      "2                                    105.5   \n",
      "3                                     41.5   \n",
      "4                                    224.5   \n",
      "5                                     37.5   \n",
      "\n",
      "   Bachelor's degree (for example BA, BS, AB)  \\\n",
      "1                                       381.5   \n",
      "2                                       501.5   \n",
      "3                                       316.5   \n",
      "4                                       390.5   \n",
      "5                                       139.5   \n",
      "\n",
      "   Graduate degree (for example master's, professional, doctorate)  \n",
      "1                                              139.5                \n",
      "2                                              147.5                \n",
      "3                                              178.5                \n",
      "4                                              112.5                \n",
      "5                                               70.5                \n",
      "[140 143 144 233 482 490 524 558 561 574]\n",
      "$Government\n",
      "[1] \"B24080_007\" \"B24080_008\" \"B24080_009\" \"B24080_017\" \"B24080_018\"\n",
      "[6] \"B24080_019\"\n",
      "\n",
      "$`Private company`\n",
      "[1] \"B24080_004\" \"B24080_014\"\n",
      "\n",
      "$`Non-profit organization including tax exempt and charitable organizations`\n",
      "[1] \"B24080_006\" \"B24080_016\"\n",
      "\n",
      "$`Self-employed`\n",
      "[1] \"B24080_005\" \"B24080_010\" \"B24080_015\" \"B24080_020\"\n",
      "\n",
      "$`Working in a family business`\n",
      "[1] \"B24080_011\" \"B24080_021\"\n",
      "\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      "`summarise()` has grouped output by 'GEOID'. You can override using the\n",
      "`.groups` argument.\n",
      " [1] 140 143 144 233 339 482 490 524 558 561 574\n",
      "[1] 11\n",
      "          GEOID  Government  Private company  \\\n",
      "1  340230001011       255.5            431.5   \n",
      "2  340230001012       160.5            490.5   \n",
      "3  340230001021       200.5            533.5   \n",
      "4  340230001022       126.5            970.5   \n",
      "5  340230001023       103.5            242.5   \n",
      "\n",
      "   Non-profit organization including tax exempt and charitable organizations  \\\n",
      "1                                               20.5                           \n",
      "2                                               93.5                           \n",
      "3                                               20.5                           \n",
      "4                                              127.5                           \n",
      "5                                                0.5                           \n",
      "\n",
      "   Self-employed  Working in a family business  \n",
      "1           23.5                           0.5  \n",
      "2          166.5                           0.5  \n",
      "3            0.5                           0.5  \n",
      "4           20.5                           0.5  \n",
      "5            0.5                           0.5  \n",
      "[140 143 144 233 339 482 490 524 558 561 574]\n",
      "Sum of age:578656.0\n",
      "Sum of sex:575260.0.\n",
      "Sum of education:593299.0\n",
      "Sum of work:434494.5\n",
      "            GEOID\n",
      "1    340230001011\n",
      "2    340230001012\n",
      "3    340230001021\n",
      "4    340230001022\n",
      "5    340230001023\n",
      "..            ...\n",
      "562  340230094002\n",
      "563  340230094003\n",
      "564  340230094004\n",
      "565  340239801001\n",
      "566  340239802001\n",
      "\n",
      "[565 rows x 1 columns]\n",
      "Sum of age:578212.0\n",
      "Sum of sex:574822.0.\n",
      "Sum of education:592858.5\n",
      "Sum of work:434494.5\n",
      "0       731.5\n",
      "1       911.5\n",
      "2       755.5\n",
      "3      1245.5\n",
      "4       347.5\n",
      "        ...  \n",
      "560     386.5\n",
      "561     324.5\n",
      "562     990.5\n",
      "563      23.5\n",
      "564    2573.5\n",
      "Length: 565, dtype: float64\n",
      "Adjusted and Corrected Education Data:\n",
      "     Less than high school  Some high school  \\\n",
      "0                      0.0               0.0   \n",
      "1                     26.0              17.0   \n",
      "2                     18.0              93.0   \n",
      "3                     18.0              22.0   \n",
      "4                      8.0               0.0   \n",
      "..                     ...               ...   \n",
      "560                    0.0              20.0   \n",
      "561                    0.0              44.0   \n",
      "562                   65.0              52.0   \n",
      "563                    0.0               0.0   \n",
      "564                    2.0              62.0   \n",
      "\n",
      "     High school graduate or equivalent (for example GED)  \\\n",
      "0                                                244.0      \n",
      "1                                                227.0      \n",
      "2                                                119.0      \n",
      "3                                                380.5      \n",
      "4                                                 74.0      \n",
      "..                                                 ...      \n",
      "560                                              123.0      \n",
      "561                                              138.5      \n",
      "562                                              199.0      \n",
      "563                                               13.5      \n",
      "564                                               30.0      \n",
      "\n",
      "     Some college, but degree not received or is in progress  \\\n",
      "0                                                 84.0         \n",
      "1                                                163.0         \n",
      "2                                                 98.0         \n",
      "3                                                264.0         \n",
      "4                                                100.5         \n",
      "..                                                 ...         \n",
      "560                                               29.0         \n",
      "561                                               48.0         \n",
      "562                                              142.0         \n",
      "563                                                0.0         \n",
      "564                                              177.0         \n",
      "\n",
      "     Associate's degree (for example AA, AS)  \\\n",
      "0                                       34.0   \n",
      "1                                       67.0   \n",
      "2                                       33.0   \n",
      "3                                      173.0   \n",
      "4                                       25.0   \n",
      "..                                       ...   \n",
      "560                                      0.0   \n",
      "561                                     44.0   \n",
      "562                                      0.0   \n",
      "563                                      0.0   \n",
      "564                                     42.0   \n",
      "\n",
      "     Bachelor's degree (for example BA, BS, AB)  \\\n",
      "0                                         270.5   \n",
      "1                                         318.5   \n",
      "2                                         252.5   \n",
      "3                                         301.0   \n",
      "4                                          93.0   \n",
      "..                                          ...   \n",
      "560                                        46.0   \n",
      "561                                        19.0   \n",
      "562                                       366.5   \n",
      "563                                        10.0   \n",
      "564                                      1129.0   \n",
      "\n",
      "     Graduate degree (for example master's, professional, doctorate)  \n",
      "0                                                 99.0                \n",
      "1                                                 93.0                \n",
      "2                                                142.0                \n",
      "3                                                 87.0                \n",
      "4                                                 47.0                \n",
      "..                                                 ...                \n",
      "560                                              168.5                \n",
      "561                                               31.0                \n",
      "562                                              166.0                \n",
      "563                                                0.0                \n",
      "564                                             1131.5                \n",
      "\n",
      "[565 rows x 7 columns]\n",
      "\n",
      "Adjusted and Corrected Age Data:\n",
      "     25 to 29 years  30 to 34 years  35 to 39 years  40 to 44 years  \\\n",
      "0               3.0             0.0           146.0            28.0   \n",
      "1              37.0            47.0           197.5           109.0   \n",
      "2             116.0           205.5            50.0             0.0   \n",
      "3              80.0            63.0            99.0            46.0   \n",
      "4              16.0            41.0             0.0            45.0   \n",
      "..              ...             ...             ...             ...   \n",
      "560            60.0            47.0             0.0            99.5   \n",
      "561             0.0            96.5             0.0             3.0   \n",
      "562           117.0           149.0           291.5           134.0   \n",
      "563             0.0             0.0             9.0            14.5   \n",
      "564           578.0           519.0           740.5           570.0   \n",
      "\n",
      "     45 to 49 years  50 to 54 years  55 to 59 years  60 and 61 years  \\\n",
      "0             160.5           140.0            86.0             14.0   \n",
      "1              37.0            73.0            61.0             18.0   \n",
      "2              18.0            62.0            79.0             21.0   \n",
      "3              63.0           165.0           359.5             69.0   \n",
      "4              15.0            46.0            55.5              0.0   \n",
      "..              ...             ...             ...              ...   \n",
      "560            84.0            34.0             0.0              0.0   \n",
      "561            56.0            21.0            17.0             11.0   \n",
      "562            64.0            76.0            11.0             14.0   \n",
      "563             0.0             0.0             0.0              0.0   \n",
      "564            81.0             2.0            53.0              2.0   \n",
      "\n",
      "     62 to 64 years  65 and 66 years  67 to 69 years  70 to 74 years  \\\n",
      "0              28.0             40.0             0.0            30.0   \n",
      "1              90.0             29.0            79.0           109.0   \n",
      "2              55.0             38.0            93.0             0.0   \n",
      "3              71.0             21.0            48.0            64.0   \n",
      "4              17.0              0.0             8.0            18.0   \n",
      "..              ...              ...             ...             ...   \n",
      "560            29.0              0.0             0.0            29.0   \n",
      "561            11.0              2.0             8.0            81.0   \n",
      "562            41.0             12.0            29.0            37.0   \n",
      "563             0.0              0.0             0.0             0.0   \n",
      "564             2.0              2.0             2.0             2.0   \n",
      "\n",
      "     75 to 79 years  80 to 84 years  \n",
      "0              37.0            19.0  \n",
      "1              25.0             0.0  \n",
      "2              18.0             0.0  \n",
      "3              29.0            68.0  \n",
      "4              52.0            34.0  \n",
      "..              ...             ...  \n",
      "560             4.0             0.0  \n",
      "561            18.0             0.0  \n",
      "562             0.0            15.0  \n",
      "563             0.0             0.0  \n",
      "564            18.0             2.0  \n",
      "\n",
      "[565 rows x 14 columns]\n",
      "\n",
      "Adjusted and Corrected Sex Data:\n",
      "       Male  Female\n",
      "0     201.0   530.5\n",
      "1     494.5   417.0\n",
      "2     335.0   420.5\n",
      "3     649.5   596.0\n",
      "4     140.0   207.5\n",
      "..      ...     ...\n",
      "560   198.5   188.0\n",
      "561   110.0   214.5\n",
      "562   579.5   411.0\n",
      "563    12.5    11.0\n",
      "564  1356.5  1217.0\n",
      "\n",
      "[565 rows x 2 columns]\n",
      "Total Sum of Corrected Age Constraints:\n",
      "434494.5\n",
      "\n",
      "Total Sum of Corrected Sex Constraints:\n",
      "434494.5\n",
      "\n",
      "Total Sum of Corrected Education Constraints:\n",
      "434494.5\n",
      "\n",
      "Total Sum of Corrected Work Constraints:\n",
      "434494.5\n",
      "\n",
      "Row sums comparison between corrected constraints:\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "(330, 14)\n",
      "(330, 2)\n",
      "(330, 7)\n",
      "(330, 5)\n",
      "565\n",
      "330\n",
      "14\n",
      "2\n",
      "7\n",
      "5\n",
      "Weights dimensions: (330, 565)\n",
      "Row sums for ind_agg1:\n",
      " 0       712.5\n",
      "1       911.5\n",
      "2       755.5\n",
      "3      1177.5\n",
      "4       313.5\n",
      "        ...  \n",
      "560     386.5\n",
      "561     324.5\n",
      "562     975.5\n",
      "563      23.5\n",
      "564    2571.5\n",
      "Length: 565, dtype: float64\n",
      "Row sums for cons:\n",
      " 0       712.5\n",
      "1       911.5\n",
      "2       755.5\n",
      "3      1177.5\n",
      "4       313.5\n",
      "        ...  \n",
      "560     386.5\n",
      "561     324.5\n",
      "562     975.5\n",
      "563      23.5\n",
      "564    2571.5\n",
      "Length: 565, dtype: float64\n",
      "Are row sums equal:\n",
      " 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "560    False\n",
      "561    False\n",
      "562    False\n",
      "563    False\n",
      "564    False\n",
      "Length: 565, dtype: bool\n",
      "Row sums for ind_agg2:\n",
      " 0       225.082769\n",
      "1       494.500000\n",
      "2       335.000000\n",
      "3       703.224787\n",
      "4       173.537777\n",
      "          ...     \n",
      "560     198.500000\n",
      "561     110.000000\n",
      "562     590.100913\n",
      "563      12.500000\n",
      "564    1358.216638\n",
      "Length: 565, dtype: float64\n",
      "Row sums for cons:\n",
      " 0       220.0\n",
      "1       494.5\n",
      "2       335.0\n",
      "3       717.5\n",
      "4       174.0\n",
      "        ...  \n",
      "560     198.5\n",
      "561     110.0\n",
      "562     594.5\n",
      "563      12.5\n",
      "564    1358.5\n",
      "Length: 565, dtype: float64\n",
      "Are row sums equal:\n",
      " 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "560    False\n",
      "561    False\n",
      "562    False\n",
      "563    False\n",
      "564    False\n",
      "Length: 565, dtype: bool\n",
      "Row sums for ind_agg3:\n",
      " 0      1052.216681\n",
      "1      1275.467255\n",
      "2      1007.551610\n",
      "3      1901.099715\n",
      "4       518.836237\n",
      "          ...     \n",
      "560     335.818462\n",
      "561     512.103490\n",
      "562    1217.161169\n",
      "563      35.162024\n",
      "564    2325.199516\n",
      "Length: 565, dtype: float64\n",
      "Row sums for cons:\n",
      " 0      1163.0\n",
      "1      1235.5\n",
      "2      1034.0\n",
      "3      1754.5\n",
      "4       508.0\n",
      "        ...  \n",
      "560     406.0\n",
      "561     508.0\n",
      "562    1235.5\n",
      "563      34.5\n",
      "564    2659.0\n",
      "Length: 565, dtype: float64\n",
      "Are row sums equal:\n",
      " 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "560    False\n",
      "561    False\n",
      "562    False\n",
      "563    False\n",
      "564    False\n",
      "Length: 565, dtype: bool\n",
      "Row sums for ind_agg4:\n",
      " 0       735.342057\n",
      "1       924.475502\n",
      "2       760.101832\n",
      "3      1258.350498\n",
      "4       347.000000\n",
      "          ...     \n",
      "560     386.000000\n",
      "561     324.000000\n",
      "562    1014.687964\n",
      "563      23.000000\n",
      "564    3291.449411\n",
      "Length: 565, dtype: float64\n",
      "Row sums for cons:\n",
      " 0       830.0\n",
      "1      1004.0\n",
      "2       897.0\n",
      "3      1332.0\n",
      "4       394.0\n",
      "        ...  \n",
      "560     554.5\n",
      "561     355.0\n",
      "562    1156.0\n",
      "563      23.0\n",
      "564    3704.5\n",
      "Length: 565, dtype: float64\n",
      "Are row sums equal:\n",
      " 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "560    False\n",
      "561    False\n",
      "562    False\n",
      "563    False\n",
      "564    False\n",
      "Length: 565, dtype: bool\n",
      "Correlation between ind_agg0 and cons: 0.31360073114084186\n",
      "Correlation between ind_agg1 and cons: 0.47008260963900633\n",
      "Correlation between ind_agg2 and cons: 0.4813647948340148\n",
      "Correlation between ind_agg3 and cons: 0.5302336918529105\n",
      "Correlation between ind_agg4 and cons: 0.8913571498379006\n",
      "          GEOID             AGE EGENID_BIRTH  \\\n",
      "0  340230001011  45 to 49 years       Female   \n",
      "1  340230001011  45 to 49 years       Female   \n",
      "2  340230001011  45 to 49 years       Female   \n",
      "3  340230001011  45 to 49 years       Female   \n",
      "4  340230001011  45 to 49 years       Female   \n",
      "\n",
      "                                               EEDUC  \\\n",
      "0  Graduate degree (for example master's, profess...   \n",
      "1  Graduate degree (for example master's, profess...   \n",
      "2  Graduate degree (for example master's, profess...   \n",
      "3  Graduate degree (for example master's, profess...   \n",
      "4  Graduate degree (for example master's, profess...   \n",
      "\n",
      "                                            KINDWORK                   TWDAYS  \n",
      "0  Non-profit organization including tax exempt a...  Yes, for 5 or more days  \n",
      "1  Non-profit organization including tax exempt a...  Yes, for 5 or more days  \n",
      "2  Non-profit organization including tax exempt a...  Yes, for 5 or more days  \n",
      "3  Non-profit organization including tax exempt a...  Yes, for 5 or more days  \n",
      "4  Non-profit organization including tax exempt a...  Yes, for 5 or more days  \n"
     ]
    }
   ],
   "source": [
    "# Edit cell to run IPF on single phase\n",
    "conn = sqlite3.connect(db_path)\n",
    "table_name = \"Phase_4_2_HPS_Phase4_2Cycle09_PUF_CSV(Aug20_Sep16)2024_hps_04_02_09_puf\"\n",
    "ind_data = pd.read_sql_query(f'SELECT * FROM \"{table_name}\"', conn)\n",
    "logger.info(f\"Starting processing for {table_name}\")\n",
    "ind_data_new,ind_full_new,new_brks,new_labs,edu_labs,work_labs,gender_name,twday_name = filter_data(MSACODE,STATECODE,ind_data)\n",
    "con_age,con_sex = con_age_func(new_brks,new_labs,statename,countyname)\n",
    "con_edu = con_edu_func(edu_labs,statename,countyname)\n",
    "con_work = con_work_func(work_labs,statename,countyname)\n",
    "cons,con_age,con_sex,con_edu,con_work,geoids = constraint_build(con_age,con_sex,con_edu,con_work)\n",
    "ints_df = ipfmain(cons,con_age,con_sex,con_edu,con_work,ind_data_new,ind_full_new,geoids,gender_name,twday_name)\n",
    "ints_df.to_csv(\"New Jersey/Middlesex County, NJ/{}_synthetic_population.csv\".format(table_name))\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rasa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
